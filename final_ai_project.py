# -*- coding: utf-8 -*-
"""Final AI Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CpOJp4y8EpyvMdcQxZPeeJp-Tl99016S
"""

#from google.colab import drive
#drive.mount('/content/drive')

#pip install fuzzywuzzy

#Import required libaries
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors
import pickle
import ast
from fuzzywuzzy import fuzz
from fuzzywuzzy import process

#!pip install kneed
from kneed import KneeLocator

#Opening files and setting up
ratings = pd.read_csv('ratings_small.csv')
ratings.shape

movies_metadata_df = pd.read_csv("movies_metadata.csv")
movies_metadata_df.head()

ratings.info()

ratings.drop("timestamp",axis=1,inplace=True)

movies = np.unique(ratings['movieId'])[:7500]
ratings = ratings.loc[ratings['movieId'].isin(movies)]
ratings.shape

ratings.info()

movie_metadata =  movies_metadata_df[['id','title', 'genres']]

movie_metadata

#Cleaning data for KNN
movie_metadata['id'] = pd.to_numeric(movie_metadata['id'], errors='coerce')

movie_metadata.dropna(subset=['id'], inplace=True)

movie_metadata['id'] = movie_metadata['id'].astype(int)

movie_data = ratings.merge(movie_metadata, left_on='movieId', right_on='id')

final_ratings = ratings.pivot(index='userId',columns='movieId',values='rating')
final_ratings.fillna(0,inplace=True)
final_ratings

user_matrix = final_ratings.copy()

zero_elements = (final_ratings == 0).sum().sum()
total_elements = final_ratings.size

ratings_sparsity = zero_elements / total_elements
print(f"Sparsity of the matrix: {ratings_sparsity * 100:.2f}%")

final_ratings.columns = final_ratings.columns.astype(str)
final_ratings.index = final_ratings.index.astype(str)

csr_data = csr_matrix(final_ratings.values)
final_ratings.reset_index(inplace=True)

user_matrix.shape

#create knn model
knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)
knn.fit(user_matrix)

#pickle for knn
with open('knn_model.pkl', 'wb') as file:
    pickle.dump(knn, file)

with open('knn_model.pkl', 'rb') as file:
    loaded_knn = pickle.load(file)

#KMeans Clustering Data Preparation
users = np.unique(ratings['userId'])[:650]
ratings = ratings.loc[ratings['userId'].isin(users)]
ratings.shape

users_favourite_movies = ratings.loc[:, ['userId', 'movieId']]
users_favourite_movies = ratings.reset_index(drop = True)
users_favourite_movies.head()

users_list = np.unique(users_favourite_movies['userId'])

user_movie_list = []
for u in users_list:
    movies = list(users_favourite_movies[users_favourite_movies['userId'] == u]['movieId'])
    movies_string = str(movies).split('[')[1].split(']')[0]
    user_movie_list.append(movies_string)

#vectorise user_movie_list to create sparseMartix
#sparseMartix: Allows each user's userIds to be matched to each movieId of the movies they reated sinces there were mutliple user inputs
vectorizer = TfidfVectorizer(token_pattern=r'[^\,\ ]+', lowercase=False)
sparseMatrix = vectorizer.fit_transform(user_movie_list)

#Converts the vectorized matrix to an array
sparse_matrix_array = sparseMatrix.toarray()
feature_names = vectorizer.get_feature_names_out()

sparse_matrix_array

feature_names

sparsematrix_df = pd.DataFrame(sparse_matrix_array, columns=feature_names)
sparsematrix_df.head()

#Kmeans model
inertias = []
differences = []

for k in range(1, 11):
  kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
  kmeans.fit(sparsematrix_df)
  inertias.append(kmeans.inertia_)

#This calculates the differences between each two consecutive clusters
for i in range(len(inertias)-1):
  differences.append(inertias[i] - inertias[i+1])

differences

#Ploting Elbow for number of clusters
plt.plot(range(1, 11), inertias)
plt.xlabel('Number of clusters (k)')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal k')
plt.show()

from kneed import KneeLocator
kl = KneeLocator(range(1,11),inertias ,curve="convex",direction ="decreasing")
print(kl.elbow)

kmeans = KMeans(n_clusters=kl.elbow, init = 'k-means++', random_state=42)
user_cluster = kmeans.fit_predict(sparsematrix_df)

#pickle for kmeans
with open('kmeans_model.pkl', 'wb') as file:
    pickle.dump(kmeans, file)

with open('kmeans_model.pkl', 'rb') as file:
    loadedkmeans = pickle.load(file)

#cleaning clusters
user_clusters = pd.DataFrame(np.concatenate((users_list.reshape(-1,1), user_cluster.reshape(-1,1)), axis = 1), columns = ['userId', 'Cluster'])
user_clusters.head()

user_cluster_summary = user_clusters.groupby('Cluster').mean()
user_cluster_summary

users_data = users_favourite_movies.loc[:, ['userId', 'movieId']]
users_data.head()

#Scores for model
from sklearn.metrics import silhouette_score, calinski_harabasz_score, adjusted_rand_score

s_score = silhouette_score(sparsematrix_df, user_cluster)
print('Silhouette Score:', s_score)
#Measures the quality of the clustering. 
#It evaluates how similar an object is to its own cluster compared to other clusters.
#0.03135026871336518: 
#This score is quite low
#The clusters are not well separated and there is significant overlap between them.

c_score = calinski_harabasz_score(sparsematrix_df, user_cluster)
print('Calinski Harabasz Score:', c_score)
#Evaluates the cluster dispersion and separation.
#14.6598275068559
#This score is also relatively low
# The dispersion between the clusters is not significantly higher than the dispersion within the clusters.

wcss_score = kmeans.inertia_
print('Within Cluster Sum of Squares:', wcss_score)
#Measures the total variance within clusters
#572.93457712321
#The total variance within the clusters.

#Graphs
#PCA Plot
#Visualize the clusters in 2D space after reducing the dimensionality of the data.
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
principal_components = pca.fit_transform(sparsematrix_df)
pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])
pca_df['Cluster'] = user_cluster

plt.figure(figsize=(10, 8))
for cluster in range(kl.elbow):
    clustered_data = pca_df[pca_df['Cluster'] == cluster]
    plt.scatter(clustered_data['PC1'], clustered_data['PC2'], label=f'Cluster {cluster}',cmap='viridis')

plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA of Clusters')
plt.legend()
plt.show()

#K-means clustering plot
#Visualize the clustering results along with the cluster centers.
from sklearn.datasets import make_blobs

num_features = sparsematrix_df.shape[1]
X, _ = make_blobs(n_samples=100, n_features=num_features, centers=kl.elbow, random_state=42)
kmeans.fit(X)
y_pred = kmeans.predict(X)

plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='viridis')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='^', s=100, linewidth=2, c=[0, 1, 2,3], cmap='viridis')
plt.title('K-Means Clustering')
plt.xlabel("Feature 0")
plt.ylabel("Feature 1")
plt.show()

#Combines the users_data dataframe and users_clusters dataframe
merged_data = pd.merge(users_data, user_clusters, on='userId')
grouped_data = merged_data.groupby(['Cluster', 'movieId']).size().reset_index(name='Count')

movie_clusters = {cluster: df.sort_values(by='Count', ascending=False).reset_index(drop=True)
                       for cluster, df in grouped_data.groupby('Cluster')}

movie_clusters

for i in range(4):
    len_users = user_clusters[user_clusters['Cluster'] == i].shape[0]
    print('Users in Cluster ' + str(i) + ' -> ', len_users)

movies_metadata_df = movies_metadata_df.loc[
                  movies_metadata_df['id'].isin(list(map(str, np.unique(users_favourite_movies['movieId']))))].reset_index(drop=True)
movies_metadata_df

#Creates a list of the movie ids associated with the passed user id
def get_user_favorite_movieid(user_id, users_data):
  userMovies = list(users_data[users_data['userId'] == user_id]['movieId'])
  return userMovies

user_fav_movies_id = get_user_favorite_movieid(1, users_data)

user_fav_movies_id

#returns a list of the names and genres of the movie_ids derived from the list returned by the previous function
def get_user_favorite_movies(user_movies, movies_metadata):
    print('User favorite movies: ')
    user_fav_movies = []

    for movie in user_movies:
        title = list(movies_metadata.loc[movies_metadata['id'] == str(movie)]['original_title'])
        if title:
            print('Movie title: ', title, ', Genres: [', end='')
            genres_str = movies_metadata.loc[movies_metadata['id'] == str(movie)]['genres'].values[0]
            # Handle potential non-string values or invalid formats
            if isinstance(genres_str, str):
                try:
                    genres = ast.literal_eval(genres_str)
                    for genre in genres:
                        print(genre['name'], ', ', end='')
                except (ValueError, SyntaxError):
                    print(f"Invalid genres data for movie ID {movie}: {genres_str}")
            else:
                print(f"Non-string genres data for movie ID {movie}: {genres_str}")
            print(end='\b\b]')
            print('')
            user_fav_movies.append(movie)

    return user_fav_movies

movies_metadata_df

user_fav_movies = get_user_favorite_movies(user_fav_movies_id,movies_metadata_df)

user_fav_movies

#Gets the specific cluster each movie in the user_fave_movie_id belongs to
def get_each_movie_cluster(user_movies):
  movie_cluster = {}
  for movie in user_movies:
    for cluster_id, df in movie_clusters.items():
      if movie in df['movieId'].values:
        movie_cluster[movie] = cluster_id
        break

  return movie_cluster

m_clusters = get_each_movie_cluster(user_fav_movies_id)
m_clusters

#Gets the exact cluster a user belongs to
def get_user_cluster(user_id,user_clusters):
    user_cluster = int(user_clusters[user_clusters['userId'] == user_id]['Cluster'])
    return user_cluster

user_cluster = get_user_cluster(1,user_clusters)

user_cluster

#Returns a list of recommendations for a user based on the cluster they belong to
def get_total_recommendations(user_fav_movies, user_cluster, movie_clusters):
  cluster_movies_list = movie_clusters.copy()
  recommendations = {}
    #removes the user's favorite movies from the list of movies within the cluster
  user_recommended_movies = []
  for movie in user_fav_movies:
    if movie in movie_clusters:
      cluster_movies_list.remove(movie)

  recommendations = {k: v for k, v in cluster_movies_list.items() if k == user_cluster}
    #The boolean values verify whether or not there are recommendations available for each user
  if recommendations:
    user_recommended_movies = [True, recommendations]
  else:
    user_recommended_movies = [False, "No recommendations available"]
  return user_recommended_movies

movie_clusters

user_recommended_movies = get_total_recommendations(user_fav_movies, user_cluster, movie_clusters)

user_recommended_movies

#Out of the total recommendations, 10 are chosen to present to the user
def get_10_recommendations(user_movie_recommendations, movies_metadata):
    recommendations_dict = user_movie_recommendations[1]

    for cluster_id, df in recommendations_dict.items():
        for index, row in df.iloc[:20].iterrows():
            movie_id = row['movieId']
            title = movies_metadata.loc[movies_metadata['id'] == str(movie_id), 'original_title'].tolist()
            if title:
                print(f'Movie title: {title}, Genres: [', end='')
                genres_str = movies_metadata.loc[movies_metadata['id'] == str(movie_id), 'genres'].values[0]
                genres = ast.literal_eval(genres_str)
                for genre in genres:
                    print(f"{genre['name']}, ", end='')
                print('\b\b]', end='')
                print()

user_recommended_movies

#if user_recommended_movies[0] == True:
if user_recommended_movies[0]==True:
  get_10_recommendations(user_recommended_movies,movies_metadata_df)

#Takes user input on the names of movies the user likes, checks if it is in the movie_metadata dataframe and recommends based on the cluster the movies would fall under
def recommend_based_on_movie_names(movie_names, movies_metadata, cluster_movies_data):
    movie_ids = []
    for movie_name in movie_names:
        movie_id = movies_metadata[movies_metadata['original_title'].str.lower() == movie_name.strip().lower()]['id'].values
        if movie_id.size > 0:
          movie_ids.append(movie_id[0])

    user_fav_movies = [int(m_id) for m_id in movie_ids]
    clusters = []

    for movie_id in user_fav_movies:
        for cluster_id, df in cluster_movies_data.items():
            if movie_id in df['movieId'].values:
                clusters.append(cluster_id)

    if clusters:
        user_cluster = clusters[0]
        user_recommended_movies = get_total_recommendations(user_fav_movies, user_cluster, cluster_movies_data)
        return user_recommended_movies
    else:
        return [False, "No recommendations available"]

#Takes in user input
movie_names = input("Enter the names of movies you like, separated by commas: ").split(',')

user_recommended_movies = recommend_based_on_movie_names(movie_names, movies_metadata_df, movie_clusters)

user_recommended_movies

#if user_recommended_movies[0]==True:
if user_recommended_movies[0] == True:
  get_10_recommendations(user_recommended_movies, movies_metadata_df)

#Collaborative filtering model
def movie_recommender_engine(movie_name, matrix, cf_model, n_recs):
    cf_model.fit(matrix)

    # Extract input movie title using fuzzy matching
    matched_movie = process.extractOne(movie_name, movie_metadata['title'])
    if matched_movie:
        movie_id = matched_movie[2]
    else:
        return "Movie not found. Please check your input."

    if movie_id not in matrix.columns:
        return "Movie not found in ratings. Please check your input."

    # Create a vector for the movie
    movie_vector = np.zeros(matrix.shape[1])  # Shape (7454,)
    movie_vector[matrix.columns.get_loc(movie_id)] = matrix[movie_id].values.mean()  # Fill in the rating

    movie_vector = movie_vector.reshape(1, -1)

    # Calculate neighbor distances
    distances, indices = cf_model.kneighbors(movie_vector, n_neighbors=n_recs)

    movie_rec_ids = sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:n_recs]

    cf_recs = []
    for i in movie_rec_ids:
        cf_recs.append({'Title': movie_metadata['title'][i[0]], 'Distance': i[1]})

    df = pd.DataFrame(cf_recs, index=range(1, n_recs + 1))

    return df

#reshape to have shape of (1, 7454)

user_matrix[1].values.reshape(1,-1).shape

movie_recs = movie_recommender_engine("Jumanji",user_matrix,knn,10)

movie_recs

#saves movie_metadata_df
movies_metadata_df.to_csv('movies_metadata_saved.csv', index=False)

